---
title: "Actividad03"
author: "Yangyang Li"
date: "3/4/2019"
output: html_document
toc: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r,echo=FALSE,warning=FALSE,message=FALSE}
library(nnet)
library(rminer)
library(caret)
library(pROC)
library(plotly)
library(e1071)
library(FSelector)
library(rpart)
library(ggpubr)
library(gridExtra)
library(caret)
library(rminer)
library(rpart.plot)
```
#title


##Estudiar funcionamiento de Artificial Neural Network, Support Vector Machine, Decision Tree y ajuste de sus par√°metros.
###Cargar de datos y fijar modelo:
```{r}
data<-read.table(file="/Users/yangyangli/Downloads/datos_icb.txt",sep=" ", dec=".", header=TRUE)
formula <- as.simple.formula(cfs(recid ~ ., data), "(recid=='SI')*1.0")
index <- holdout(ratio=0.75,data$recid,mode = "stratified")
d.train <- data[index$tr,]
d.test  <- data[index$ts,]
```
###Neural Network
####Size
N??mero de neuronas en la capa oculta depende de:<br>
-Los n??meros de unidades de entrada y salida.<br>
-La complejidad de la funci??n o clasificaci??n a aprender.<br>
-El algoritmo de entrenamiento,etc <br>
Con muy pocas unidades ocultas, obtendr??amos alto error de entrenamiento,  pero si usamos demasiadas unidades ocultas, puede obtener un error de entrenamiento bajo, pero obtendremos un alto error de generalizaci??n debido al sobreajuste y alta variaci??n.<br>
A continuaci??n se muestra los valores de auc bajo diferentes numero de neuronas:
```{r,warning=FALSE}
  size=seq(1,11,by=1)
   auc.size<-sapply(size, function(x){
    modelo2 <-  nnet(formula,data=d.train,size=x,maxit=1000, decay=0.013,trace=FALSE)
    predict.test <- predict(modelo2,d.test,type="raw")
    auc(d.test$recid,predict.test)[1]
  })
  ggplot(data = as.data.frame(auc.size), mapping = aes(y = auc.size, x = size)) + geom_point(color="blue")
```

Como se muestra en la figura, podemos ver que alto n??mero de  neuronas causan una disminuci??n en el auc generalizado, lo que significa que se ha producido overfitting.<br>
####decay
Weight decay. Default 0.<br>
El weight decay es para evitar overfitting, a continuaci??n vamos a buscar un rango adecuado para el decay.
```{r,warning=FALSE}
  decay1=seq(0,1,by=1e-3)
  auc.decay1<-sapply(decay1, function(x){
    modelo1 <-  nnet(formula,data=d.train,size=3,maxit=1000, decay=x,trace=FALSE)
    predict.test <- predict(modelo1,d.test,type="raw")
    auc(d.test$recid,predict.test)[1]
  })
  decay2=seq(0,0.003,by=1e-4)
  auc.decay2<-sapply(decay2, function(x){
    modelo1 <-  nnet(formula,data=d.train,size=3,maxit=1000, decay=x,trace=FALSE)
    predict.test <- predict(modelo1,d.test,type="raw")
    auc(d.test$recid,predict.test)[1]
  })
 p1 <- ggplot(data = as.data.frame(auc.decay1), mapping = aes(y = auc.decay1, x = decay1)) +geom_point(color="blue")
 p2 <- ggplot(data = as.data.frame(auc.decay2), mapping = aes(y = auc.decay2, x = decay2)) + geom_point(color="blue")
grid.arrange(p1,p2)
```

A trav??s de las pruebas, encontramos que el mejor valor de atenuaci??n es muy peque??o, incluso cerca de cero.<br>

####Mejor combinaci??n de parametros
```{r,warning=FALSE}
parameter.nnet <- function(d.train,d.test,formula){
       m <- expand.grid(size=seq(2,5,by=1),decay=seq(0,0.003,by=0.0005))
       auc <- vector()
       for (i in 1:dim(m)[1]) {
        set.seed(5)
        modelo <-  nnet(formula,data=d.train,size=m$size[i],maxit=500, decay=m$decay[i],trace=FALSE)
        predict.test <- predict(modelo,d.test,type="raw")
        auc.test <- auc(d.test$recid,predict.test)[1]
        auc <- append(auc,auc.test)
       } 
       m$auc <- auc
  return(m)
}
p.nnet <- parameter.nnet(d.train,d.test,formula)
p.nnet[which.max(p.nnet$auc),]
```

```{r}
plot_ly(p.nnet, z = ~auc, y = ~size, x = ~decay)
```

###Support Vector Machine
####cost
El cost es el factor de penalizaci??n, es decir la tolerancia para el error. Cuanto mayor es la cost, menor es la tolerancia para el error, pero puede causar overfitting . Cuanto menor es el cost, m??s error aparece.el valor de cost influye la capacidad de generalizaci??n.
```{r}
  cost1=seq(100,1000,by=100)
  auc.cost1<-sapply(cost1, function(x){
      modelo3 <-  svm(formula,data=d.train,cost=x,probability=TRUE)
      predict.test <- predict(modelo3,d.test,probability=TRUE)
     # svm.pred <- attr(predict.test, which="probabilities")[,"SI"]
      auc.test <- auc(d.test$recid,predict.test)
  })
  cost2=seq(1,200,by=10)
  auc.cost2<-sapply(cost2, function(x){
      modelo3 <-  svm(formula,data=d.train,cost=x,probability=TRUE)
      predict.test <- predict(modelo3,d.test,probability=TRUE)
     # svm.pred <- attr(predict.test, which="probabilities")[,"SI"]
      auc.test <- auc(d.test$recid,predict.test)
  })
   p1 <- ggplot(data = as.data.frame(auc.cost1), mapping = aes(y = auc.cost1, x = cost1)) + geom_point(color="blue")
   p2 <- ggplot(data = as.data.frame(auc.cost2), mapping = aes(y = auc.cost2, x = cost2)) + geom_point(color="blue")
   grid.arrange(p1,p2)
```

####gamma
Gamma es un par??metro de la funci??n kernel??? El valor predeterminado es 1 / n_features.
Cuanto m??s grande el gamma, menos vectores de soporte, menor  el valor gamma y m??s vectores de soporte. El n??mero de vectores de soporte afecta a la velocidad de entrenamiento y predicci??n.
```{r}
  gamma1=seq(0.01,1,by=0.1)
   r.gamma1<-sapply(gamma1, function(x){
     modelo4 <-  svm(formula,data=d.train,gamma=x,probability=TRUE)
     predict.test <- predict(modelo4,d.test,probability=TRUE)
     #svm.pred <- attr(predict.test, which="probabilities")[,"SI"]
     auc.test <- auc(d.test$recid,predict.test)
  })
   gamma2=10^(-5:-1)
   r.gamma2<-sapply(gamma2, function(x){
     modelo4 <-  svm(formula,data=d.train,gamma=x,probability=TRUE)
     predict.test <- predict(modelo4,d.test,probability=TRUE)
     #svm.pred <- attr(predict.test, which="probabilities")[,"SI"]
     auc.test <- auc(d.test$recid,predict.test)
  })
   p1 <- ggplot(data = as.data.frame(r.gamma1), mapping = aes(y = r.gamma1, x = gamma1)) + geom_point(color="blue")
   p2 <- ggplot(data = as.data.frame(r.gamma2), mapping = aes(y = r.gamma2, x = gamma2)) + geom_point(color="blue")
    grid.arrange(p1,p2)
```

####Mejor combinaci??n de parametros
```{r,warning=FALSE}
parameter.svm <- function(d.train,d.test,formula){
       m <- expand.grid(cost=seq(0,500,by=100),gamma=10^(-5:-3))
      auc <- vector()
      for (i in 1:dim(m)[1]) {
        modelo <-  svm(formula,data=d.train,size=m$cost[i],gamma=m$gamma[i],probability=TRUE)
        predict.test <- predict(modelo,d.test,probability=TRUE)
        auc.test <- auc(d.test$recid,predict.test)[1]
        auc <- append(auc,auc.test)
      }
   m$auc <- auc
  return(m )
}
p.svm <- parameter.svm(d.train,d.test,formula)
p.svm[which.max(p.svm$auc),]


tuned <- tune.svm(recid ~., data = d.train, gamma = 10^(-6:-1), cost = seq(100,500,by=100)) # tune
summary (tuned) 
```

```{r}
plot_ly(p.svm, z = ~auc, x = ~cost, y = ~gamma)
```
###Decision Tree
####control
```{r}
cp=c(0.5,0.05,0.005,0.0005)
  for (i in 1:3) {
    dt.fit <- rpart(recid~., data=d.train,control=rpart.control(cp=cp[i]))
     rpart.plot(dt.fit, branch=1, branch.type=2, type=1, extra=102,
             shadow.col="gray", box.col="green",
             border.col="blue", split.col="red",
             split.cex=1.2, main="DTree")
  }
  r.DT<-sapply(cp, function(x){
     dt.fit <- rpart(recid~., data=d.train, control=rpart.control(cp=x))
     dt.pred <- predict(dt.fit,d.test,type="prob")[,"SI"]
     auc.test <- auc(d.test$recid,dt.pred)
  })
  r.DT
  ggplot(data = as.data.frame(r.DT), mapping = aes(y = r.DT, x = cp)) + geom_point(color="blue")

```

##funci??n necesario para k_fold
```{r,warning=FALSE}
estimaMetrica <- function(d.train,d.test,formula,modelo,parameters){
      if(modelo=="glm"){
        modelo <- glm(formula,data=d.train,family = binomial("logit"))
        predict.test <- predict(modelo,d.test,type="response")
        auc.test <- auc(d.test$recid,predict.test)
        }
      if(modelo=="nnet"){
        modelo <- nnet(formula,data = d.train,size=parameters$size,maxit=1000,decay=parameters$decay,trace=FALSE)
        predict.test <- predict(modelo,d.test,type="raw")
        auc.test <- auc(d.test$recid,predict.test)
      } 
      if(modelo=="svm"){
        modelo <-  svm(formula,data=d.train,size=parameters$cost,gamma=parameters$gamma,probability=TRUE)
        predict.test <- predict(modelo,d.test,probability=TRUE)
        auc.test <- auc(d.test$recid,predict.test)
      } 
      if(modelo=="dt"){
        dt.fit <- rpart(recid~., data=d.train, control=rpart.control(cp=0.005))
        dt.pred <- predict(dt.fit,d.test,type="prob")[,"SI"]
        auc.test <- auc(d.test$recid,dt.pred)
      }
      return(auc.test)
}
estimaMetrica(d.train,d.test,formula,"glm")
estimaMetrica(d.train,d.test,formula,"nnet",parameters.nnet )
estimaMetrica(d.train,d.test,formula,"svm",parameters.svm )
estimaMetrica(d.train,d.test,formula,"dt")
```


```{r,warning=FALSE}
double.k_fold <- function(data,k1,modelo){
  k=seq(1,k1,by=1)
 folds <- createFolds(data$recid,k=k1)
 df <- vector()
  for (i in 1:k1) {
   d.test <- data[folds[[i]],]
    ks <- k[-i]
    r <- lapply(ks, function(x){
    d.selection <- data[x,]
    d.train <- data[-c(x,folds[[i]]),]
    
    formula <- as.simple.formula(cfs(recid ~., data), "recid")
    if(modelo=="nnet"){
       parameter <- parameter.nnet(d.train,d.test,formula)
    }
    if(modelo=="svm"){
       parameter <- parameter.svm(d.train,d.test,formula)
    }
    p <- parameter[which.max(parameter$auc),]
    metrica <- estimaMetrica(d.train,d.test,formula,modelo,p)[1]
   })
    df <- cbind(df,r)
  }
return(df)
}
x <- double.k_fold(data,10,"nnet")
glm <- k_fold(data,10,"glm")
net <- k_fold(data,10,"nnet",parameters.nnet)




```

###seleccionn v

```{r}

#antes de estimar modelo, selection conjunto de var
# filtra
# warapper :seleccion+metrica auc
# embedded

```

?????? C?????????????????????????????????????????????c??????????????????????????????????????????,??????????????????C???????????????????????????C????????????????????????????????????
gamma?????????RBF????????????kernel?????????????????????????????????????????????????????????????????????????????????????????????????????????gamma??????????????????????????????gamma???????????????????????????????????????????????????????????????????????????????????????
??????gamma???????????????????????????????????????????????????????????????????????????????????????????????????gamma?????????????????????????????????????????????????????????????????????????????????
???????????????????????????gamma???????????????????????????gamma???????????????????????????????????????????????????????????????????????????????????????????????????C???????????????????????????

?????????gamma????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????

??????????????????????????????2????????????????????????gamma???C?????????????????????????????????????????????????????????????????????gamma?????????????????????????????????????????????????????????C????????????????????????????????????????????????????????????????????????????????????

?????????????????????????????????gamma??????????????????C?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????RBF?????????????????????????????????????????????????????????????????????????????????????????????????????????C?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????

??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????CV????????????n_splits??????????????????????????????????????????????????????????????????C???gamma????????????????????????????????????????????????


cp es la profndidad del arbol, mas profundo(numero menor) mejor clasifica, pero con overfitting 
