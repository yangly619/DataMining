---
title: "CLASE01"
author: "Yangyang Li"
date: "21/2/2019"
output: 
  html_document: 
    theme: cerulean
    toc: yes
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE???warning=FALSE)
```
#Statistical analysis and LR modelling
```{r}
library(rpart)
library(hier.part)
library(MASS)
```

###Cargar de datos

mirar que caracter separa los campos,y los que separa num decimales
.csv: sep=','
.csv: sep=';'
.table: sep=' '
univariante,bivariante,multivariante
iso-8859-1/2
t-test:t.test
necesita una medida dice una distribucion es normal o no:shapiro.test(variable)
estudia todos los variables numericas distribucion ,normal o no normal
```{r}
require(ggplot2)
data<-read.table(file="/Users/yangyangli/Downloads/datos_icb.txt",sep=" ", dec=".", header=TRUE)
head(data)
summary(data)

uniAnalisis<-function(x){
    v1 <- paste0('data$', x)
    s<-mean(v1)
    
    uniAnalisis<-s
    return(uniAnalisis)
}

plot(data$feno,cex.names=0.6)
plot(data$feno,cex.names=0.8,las=3)
grados<-table(data$grado)
barplot(grados)
pie(grados,clockwise = TRUE,labels = c("G1","G2","G3"))
hist(table(data$edad))
p <- ggplot(data = data,mapping = aes(x = data$feno, y = data$grado))
p + geom_point()
shapiro.test(data$edad)
?shapiro.test
xx<-rnorm(10)
shapiro.test(xx)
##el hipotesis nulo es normal.
#distribucion numerica.norm , p_value<0.05 rechazo el hipotesis nulo 
hist(data$edad)
#c(-inf,20,25,30,inf)
data$edad_cat<-cut(data$edad,breaks = c(0,20,25,30,max(data$edad)))
```

analisis bivariante, estudia asociacion de los variables,primer paso en estudia v.categorica.
are grade and fenotipo related?

```{r}
table(data$grado,data$feno)
barplot(table(data$grado,data$feno),cex.names = 0.75)

```
algo asociacion esperamos::
imagen:luminal solo concentra grado1
grado:independiende a tipos,pero se concentra mas en basal like mas

function:xtabs 

```{r}
quim.gr.tab<-xtabs(~quim+grado,data=data)
chisq.test(quim.gr.tab)
```

asociacion entre tam y grado (numerica y categorica)
```{r}
boxplot(data$tam~data$grado)
```
funcion utiliza para numerica y categoric

```{r}
#aov es una especie de t_test para mas de 2 variables , t_test compara la media de dos grupos 
summary(aov(tam~grado,data=data))
```

logistic regression , pa un modelo multivariante  estudia numerica vs categorica
```{r}
rlog<-glm(recid~tam,data = data,family = binomial("logit"))
```

numerica vs numerica 
```{r}
plot(data$edad,data$tam)
#coreracion rango [-1,1] ,cerca 0 significa no tiens correacion, 1 significa c.positiva y biceversa
cor(data$tam,data$edad)
#regereso lineal ,se usa cuando y es numerica, logistica se usa para y= numerica
elin<-lm(tam~edad,data = data)
```

```{r}
#funcion detecta tipo de variables
bivariantes <- function(x){
  table <- matrix(nrow=length(x),ncol=length(x)) 
  table<-as.data.frame(table)
  colnames(table)<-colnames(x)
  rownames(table)<-colnames(x)
  for (i in 1:length(x)) {
    for (j in 1:length(x)) {
      a <- colnames(table)[i]
      b <- colnames(table)[j]
      formula<-paste('~',a,'+',b)
      RegFormula <- paste(a,'~',b)
      RegFormula1 <- paste(b,'~',a)
      if(i==j){
        table[i,j]<-"X"
      }else
        if(is.factor(x[,i])&&is.factor(x[,j])){ 
        xtabs<-xtabs(formula,data=x)
        test <- chisq.test(xtabs)
        test <- as.list(test)
        table[i,j]<-round(as.numeric(test[3]),5)
        table[j,i]<-round(as.numeric(test[3]),5)
        }else
          if(is.numeric(x[,i])&&is.numeric(x[,j])){
                result <-as.list(summary(lm(RegFormula,data = x)))
                table[i,j] <- round(result$coefficients[2,4],5)
          }else
            if(is.factor(x[,i])&&is.numeric(x[,j])){
              result <-as.list(summary(glm(RegFormula,data =  x,family=binomial("logit"))))
              table[i,j] <- round(result$coefficients[2,4],5)
            }else
             if(is.numeric(x[,i])&&is.factor(x[,j])){
               result <-as.list(summary(glm(RegFormula1,data =  x,family=binomial("logit"))))
              table[i,j] <- round(result$coefficients[2,4],5)
             }
      }}
      return(table)
}
bivariantes(data[,-1])

```

```{r}
mod.i<- glm(data$recid~.,data,family=binomial("logit"))
mod.f<-stepAIC(mod.i,direction="back")
predict <- predict(mod.f,data)
#funcion acc en formato list
ACC <- function(predict,patron){
  sapply(predict, calculo(x){
    if(x<0.5){
      x=0
    }else
      x=1
  })return(predict)
}

```
para regresion linear, la columna de estimate son betas,beta0 es donde cruza el eje y 
G1 es referencia
recode permite recodificar los valores de variables categoricas(dplyr package), sirve para agrupar los grupos.

regresion linear:variab numerica~ v.lo que sea
    (lm)        :variab categorica: lm((data$recid=="SI")*1~tam,datos)
                no es recomendable usar r.linear,porque es posible dar una probabilidad>1
                hace falta aplica r.logistica, porq la probabilidad esta entre0-1,la                     r.linea sobre pasa ese valor 
regresion logistica(glm):cuando una variab dependiente es binaria ,estudia clasificacion

####
seleccion de variables (stepwise):forward,backward
dummy: variable artificial, v.categorica a 0,1 cuando aplica v categ al modelo glm,internamente hace dummy para convertir a va.numericas.
mod.i<- glm(recid~.,data,family=("logit"))
mod.f<-stepAIC(mod.i,direction="back")
AIC:calidad de modelo(como desordenada esta la distribucion de datos)
cuando mayor AIC, mas desorden de las varianzas.nos dice como de bien las variables
seleccionados.quitando variables(que son ruidos),hasta AIC no baja mas 

todo loque hemos hecho arriba son modelos explicativos,explicando la importancias de factores 

####
para saber como es bueno nuestro modelo anterior 
modelos predictivos
acierta ACC (precision)
como se calcula ACC
comparando resultados con valores real de patrones

predict(mod.f,dataframe,type="response")  sale un valor 0-1 (<05 false,>05 true)son resultados de las muestras,
luego tiene que comparar con el patron.
function acc(salida,real){
....
}
#### ultimo clase de actividad1_seleccion varibales
AIC mejor explica 
ACC mejor clasifica :exhautice search,genera todas los posibles modelos 2^8, selecciona

como consige las cominacion de modeos: combos()
